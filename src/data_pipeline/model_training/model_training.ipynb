{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo usando Random Forest no SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas e variáveis de ambiente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sklearn.model_selection import train_test_split\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente a partir de um arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Definir a região a ser usada (us-east-1)\n",
    "region_name = 'us-east-1'\n",
    "\n",
    "# Carregar variáveis de ambiente para conectar ao banco de dados RDS\n",
    "database_name = os.getenv('DATABASE_NAME')\n",
    "table_name = os.getenv('TABLE_NAME')\n",
    "rds_host = os.getenv('RDS_HOST')\n",
    "rds_port = os.getenv('RDS_PORT')\n",
    "rds_user = os.getenv('RDS_USER')\n",
    "rds_password = os.getenv('RDS_PASSWORD')\n",
    "\n",
    "# Criar uma sessão boto3\n",
    "boto3_session = boto3.Session()\n",
    "\n",
    "# Criar um cliente S3 usando a sessão boto3\n",
    "s3_client = boto3_session.client('s3')\n",
    "\n",
    "# Criar um cliente SageMaker usando a sessão boto3\n",
    "sm_boto3 = boto3_session.client('sagemaker')\n",
    "\n",
    "# Criar uma sessão SageMaker\n",
    "sess = sagemaker.Session(boto_session=boto3_session)\n",
    "\n",
    "# Obter a região da sessão boto3\n",
    "region = sess.boto_session.region_name\n",
    "\n",
    "# Definir o nome do bucket S3 a partir da variável de ambiente\n",
    "bucket = os.getenv('BUCKET_NAME')\n",
    "\n",
    "# Imprimir o nome do bucket que está sendo usado\n",
    "print(\"Usando o bucket \" + bucket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando a database do RDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar a string de conexão para o SQLAlchemy\n",
    "db_url = f'mysql+pymysql://{rds_user}:{rds_password}@{rds_host}:{rds_port}/{database_name}'\n",
    "\n",
    "# Conectar-se ao banco de dados\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Consultar o banco de dados e carregar os dados em um DataFrame\n",
    "query = f'SELECT * FROM {table_name}'\n",
    "hotel_reservas = pd.read_sql(query, con=engine)\n",
    "hotel_reservas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover as colunas que não serão utilizadas na análise ou no modelo\n",
    "hotel_reservas.drop(['Booking_ID','booking_status', 'no_of_previous_bookings_not_canceled','repeated_guest', 'no_of_previous_cancellations'], axis=1, inplace=True)\n",
    "\n",
    "# Converter as colunas categóricas em variáveis dummy (one-hot encoding)\n",
    "hotel_reservas = pd.get_dummies(hotel_reservas, prefix=['type_of_meal_plan', 'room_type_reserved', 'market_segment_type'],\n",
    "                                columns=['type_of_meal_plan', 'room_type_reserved', 'market_segment_type'])\n",
    "\n",
    "# Exibir o DataFrame transformado\n",
    "hotel_reservas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter a lista de todas as colunas do DataFrame hotel_reservas\n",
    "features = list(hotel_reservas.columns)\n",
    "\n",
    "# Exibir a lista de features (nomes das colunas)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover e obter o décimo primeiro elemento da lista de features (coluna que será usada como label)\n",
    "label = features.pop(10)\n",
    "\n",
    "# Exibir o nome da coluna que foi removida da lista de features e armazenada em label\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas restantes como variáveis independentes (features)\n",
    "x = hotel_reservas[features]\n",
    "\n",
    "# Selecionar a coluna removida anteriormente como variável dependente (label)\n",
    "y = hotel_reservas[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as primeiras cinco linhas do DataFrame x (variáveis independentes)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir as primeiras cinco linhas do DataFrame y (variáveis independentes)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir a forma (número de linhas e colunas) do DataFrame x (variáveis independentes)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir a contagem de valores únicos na série y (variável dependente)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir a forma (número de linhas e colunas) do conjunto de treinamento das variáveis independentes\n",
    "print(X_train.shape)\n",
    "\n",
    "# Exibir a forma (número de linhas e colunas) do conjunto de teste das variáveis independentes\n",
    "print(X_test.shape)\n",
    "\n",
    "# Exibir a forma (número de linhas) do conjunto de treinamento da variável dependente\n",
    "print(y_train.shape)\n",
    "\n",
    "# Exibir a forma (número de linhas) do conjunto de teste da variável dependente\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter o conjunto de treinamento das variáveis independentes para um DataFrame\n",
    "trainX = pd.DataFrame(X_train)\n",
    "\n",
    "# Adicionar a variável dependente ao conjunto de treinamento\n",
    "trainX[label] = y_train\n",
    "\n",
    "# Converter o conjunto de teste das variáveis independentes para um DataFrame\n",
    "testX = pd.DataFrame(X_test)\n",
    "\n",
    "# Adicionar a variável dependente ao conjunto de teste\n",
    "testX[label] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir a forma (número de linhas e colunas) do DataFrame de treinamento completo (variáveis independentes + dependente)\n",
    "print(trainX.shape)\n",
    "\n",
    "# Exibir a forma (número de linhas e colunas) do DataFrame de teste completo (variáveis independentes + dependente)\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o DataFrame de treinamento completo em um arquivo CSV chamado \"train-H.csv\"\n",
    "trainX.to_csv(\"train-H.csv\", index=False)\n",
    "\n",
    "# Salvar o DataFrame de teste completo em um arquivo CSV chamado \"test-H.csv\"\n",
    "testX.to_csv(\"test-H.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enviar dados para o S3. O SageMaker irá utilizar os dados de treinamento do S3\n",
    "sk_prefix = \"sagemaker/mobile_price_classification/sklearncontainer\"\n",
    "\n",
    "# upload do arquivo CSV de treinamento para o bucket S3\n",
    "trainpath = sess.upload_data(\n",
    "    path=\"train-H.csv\", bucket=bucket, key_prefix=sk_prefix\n",
    ")\n",
    "\n",
    "# upload do arquivo CSV de teste para o bucket S3\n",
    "testpath = sess.upload_data(\n",
    "    path=\"test-H.csv\", bucket=bucket, key_prefix=sk_prefix\n",
    ")\n",
    "\n",
    "# Imprimir o caminho completo do arquivo de treinamento no S3\n",
    "print(trainpath)\n",
    "\n",
    "# Imprimir o caminho completo do arquivo de teste no S3\n",
    "print(testpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do script para o SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile scriptrf.py\n",
    "\n",
    "# Importar bibliotecas necessárias\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import boto3\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "bucket = os.getenv('BUCKET_NAME')\n",
    "\n",
    "# Função para carregar o modelo a partir de um diretório\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Extraindo argumentos\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Hiperparâmetros enviados pelo cliente são passados como argumentos de linha de comando para o script\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=100)\n",
    "    \n",
    "    # Diretórios de dados, modelo e saída\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train-file\", type=str, default=\"train-H.csv\")\n",
    "    parser.add_argument(\"--test-file\", type=str, default=\"test-H.csv\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    # Lendo dados\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    # Obter a lista de features e o label\n",
    "    features = list(train_df.columns)\n",
    "    label = features.pop(-1)\n",
    "    \n",
    "    # Construir datasets de treinamento e teste\n",
    "    X_train = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    y_train = train_df[label]\n",
    "    y_test = test_df[label]\n",
    "  \n",
    "    # Treinar o modelo RandomForest\n",
    "    model = RandomForestClassifier(n_estimators=args.n_estimators, verbose=3, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Salvar o modelo treinado\n",
    "    model_path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, model_path)\n",
    "    \n",
    "    # Enviar o modelo treinado para o bucket S3\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.upload_file(model_path, bucket, \"model.joblib\")\n",
    "    \n",
    "    # Fazer previsões e avaliar o modelo\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    test_rep = classification_report(y_test, y_pred_test)\n",
    "\n",
    "    # Imprimir a acurácia do modelo e o relatório de teste\n",
    "    print('Model Accuracy is: ', test_acc)\n",
    "    print('Testing Report: ')\n",
    "    print(test_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração do SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "# Definir a versão do framework a ser usada\n",
    "FRAMEWORK_VERSION = \"1.2-1\"\n",
    "\n",
    "# Obter o nome do bucket a partir da variável de ambiente\n",
    "bucket = os.getenv('BUCKET_NAME')\n",
    "\n",
    "# Criar um estimador SKLearn para treinar o modelo no SageMaker\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"scriptrf.py\",  # Script de entrada para treinar o modelo\n",
    "    role=os.getenv('SAGEMAKER_ROLE'),  # Função do IAM para execução do SageMaker\n",
    "    instance_count=1,  # Número de instâncias a serem usadas para treinamento\n",
    "    instance_type=\"ml.m5.large\",  # Tipo de instância a ser usada para treinamento\n",
    "    framework_version=FRAMEWORK_VERSION,  # Versão do framework SKLearn\n",
    "    base_job_name=\"RF-custom-sklearn\",  # Nome base para o trabalho de treinamento\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 100,  # Hiperparâmetro para o número de estimadores do RandomForest\n",
    "    },\n",
    "    use_spot_instances=True,  # Usar instâncias spot para reduzir custos\n",
    "    max_wait=7200,  # Tempo máximo de espera em segundos para instâncias spot\n",
    "    max_run=3600,  # Tempo máximo de execução em segundos para o trabalho de treinamento\n",
    "    sagemaker_session=sess  # Sessão do SageMaker a ser usada\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento, previsões e avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar o trabalho de treinamento usando o estimador SKLearn\n",
    "sklearn_estimator.fit({\"train\": trainpath, \"test\": testpath}, wait=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
